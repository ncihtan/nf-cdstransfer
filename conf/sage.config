// ----------------------
// Config profile metadata
// ----------------------
params {
  config_profile_description = 'The Sage Bionetworks profile'
  config_profile_contact     = 'Bruno Grande (@BrunoGrandePhD)'
  config_profile_url         = 'https://github.com/Sage-Bionetworks-Workflows'
}

// ----------------------
// Global parameters / caps
// ----------------------
params {
  igenomes_base = 's3://sage-igenomes/igenomes'
  max_memory    = '128.GB'
  max_cpus      = 16
  max_time      = '240.h'
}

// ----------------------
// Use S3 for work directory (REQUIRED for AWS Batch)
// Replace <YOUR-BUCKET> with a bucket your Batch job role can R/W
// ----------------------
workDir = 's3://<YOUR-BUCKET>/nf-work'

// Optional: collect key outputs in S3 as well
// publishDir = 's3://<YOUR-BUCKET>/nf-results'

// ----------------------
// Enable Fusion v2 for direct S3 I/O (recommended)
// ----------------------
fusion {
  enabled = true
}

// ----------------------
// Retry / error handling
// ----------------------
process {
  errorStrategy = { task.exitStatus in [143,137,104,134,139,247] ? 'retry' : 'finish' }
  maxRetries    = 5
  maxErrors     = '-1'
}

// ----------------------
// File transfer tuning (kept from your original)
// ----------------------
threadPool.FileTransfer.maxAwait = '24 hour'

// ----------------------
// AWS + Executor
// ----------------------
aws {
  region = "us-east-1"
  client {
    uploadChunkSize  = 209715200
    uploadMaxThreads = 4
  }
  batch {
    maxParallelTransfers = 1
    maxTransferAttempts  = 5
    delayBetweenAttempts = '120 sec'
  }
}

executor {
  name            = 'awsbatch'
  queueSize       = 500
  submitRateLimit = '5 / 1 sec'
}

// ----------------------
// Default resources
// ----------------------
process {
  cpus   = { check_max( 1    * slow(task.attempt), 'cpus'   ) }
  memory = { check_max( 6.GB * task.attempt,       'memory' ) }
  time   = { check_max( 24.h * task.attempt,       'time'   ) }

  // Process-specific labels (available if you add label 'process_low' etc.)
  withLabel:process_low {
    cpus   = { check_max( 4     * slow(task.attempt),  'cpus'   ) }
    memory = { check_max( 12.GB * task.attempt,        'memory' ) }
    time   = { check_max( 24.h  * task.attempt,        'time'   ) }
  }
  withLabel:process_medium {
    cpus   = { check_max( 12    * slow(task.attempt), 'cpus'   ) }
    memory = { check_max( 36.GB * task.attempt,       'memory' ) }
    time   = { check_max( 48.h  * task.attempt,       'time'   ) }
  }
  withLabel:process_high {
    cpus   = { check_max( 24    * slow(task.attempt), 'cpus'   ) }
    memory = { check_max( 72.GB * task.attempt,       'memory' ) }
    time   = { check_max( 96.h  * task.attempt,       'time'   ) }
  }
  withLabel:process_long {
    time   = { check_max( 192.h  * task.attempt,   'time'   ) }
  }
  withLabel:process_high_memory {
    memory = { check_max( 128.GB * task.attempt,   'memory' ) }
  }

  // Optional: while debugging synapse downloads, set a hard timeout and fewer retries
  withName:synapse_get {
    time        = '30 min'
    errorStrategy = 'retry'
    maxRetries    = 1
    // Uncomment ONLY if your syn entity is a FOLDER:
    // ext.args = '-r'
    // Uncomment to shorten our built-in hard timeout (seconds):
    // ext.timeout_sec = 900
  }
}

// ----------------------
// Helper fns
// ----------------------
def slow(attempt, factor = 2) {
  Math.ceil( attempt / factor) as int
}

def check_max(obj, type) {
  if (type == 'memory') {
    try {
      (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1) ? (params.max_memory as nextflow.util.MemoryUnit) : obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      obj
    }
  } else if (type == 'time') {
    try {
      (obj.compareTo(params.max_time as nextflow.util.Duration) == 1) ? (params.max_time as nextflow.util.Duration) : obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      obj
    }
  } else if (type == 'cpus') {
    try {
      Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      obj
    }
  }
}
