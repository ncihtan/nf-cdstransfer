// ----------------------
// Config profile metadata
// ----------------------
params {
  config_profile_description = 'nf-cdstransfer'
  config_profile_contact     = 'Adam Taylor (@adamjtaylor)'
  config_profile_url         = 'https://github.com/ncihtan/nf-cdstransfer'
  config_notes               = """
    This profile is optimized for use with the nf-cdstransfer Nextflow workflow running AWS Batch in Seqera Platform.
    It is based on the Sage Bionetworks sage.config profile.
  """
}

// ----------------------
// Global resource caps
// ----------------------
params {
  max_memory = '128.GB'
  max_cpus   = 24
  max_time   = '240.h'
}

// ----------------------
// Retry / error handling
// ----------------------
process {
  errorStrategy = { task.exitStatus in [143,137,104,134,139,247,1] ? 'retry' : 'finish' }
  maxRetries    = 5
  maxErrors     = '-1'
}

// ----------------------
// File transfer tuning
// ----------------------
threadPool.FileTransfer.maxAwait = '24 hour'

// ----------------------
// AWS + Executor
// ----------------------
aws {
  region = 'us-east-1'
  client {
    uploadChunkSize   = 209715200
    uploadMaxThreads  = 4
  }
  batch {
    maxParallelTransfers = 1
    maxTransferAttempts  = 5
    delayBetweenAttempts = '120 sec'
  }
}

executor {
  name           = 'awsbatch'
  queueSize      = 500
  submitRateLimit = '5 / 1 sec'
}

// ----------------------
// Default resources
// ----------------------
process {
  cpus   = { check_max( 2    * slow(task.attempt), 'cpus'   ) }
  memory = { check_max( 4.GB * task.attempt,       'memory' ) }
  time   = { check_max( 24.h * task.attempt,       'time'   ) }

  // Process-specific overrides
  withName:synapse_get {
    cpus   = { check_max( 1     * slow(task.attempt), 'cpus'   ) }
    memory = { check_max( 1.GB  * task.attempt,       'memory' ) }
    time   = { check_max( 8.h   * task.attempt,       'time'   ) }
  }

  // ✅ renamed from cds_upload → crdc_upload
  withName:crdc_upload {
    cpus   = { check_max( 4     * slow(task.attempt), 'cpus'   ) }
    memory = { check_max( 2.GB  * task.attempt,       'memory' ) }
    time   = { check_max( 8.h   * task.attempt,       'time'   ) }
  }
}

// ----------------------
// Helper functions
// ----------------------
def slow(attempt, factor = 2) {
  Math.ceil(attempt / factor) as int
}

def check_max(obj, type) {
  if (type == 'memory') {
    try {
      (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1) ? (params.max_memory as nextflow.util.MemoryUnit) : obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      obj
    }
  } else if (type == 'time') {
    try {
      (obj.compareTo(params.max_time as nextflow.util.Duration) == 1) ? (params.max_time as nextflow.util.Duration) : obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      obj
    }
  } else if (type == 'cpus') {
    try {
      Math.min(obj, params.max_cpus as int)
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      obj
    }
  }
}
